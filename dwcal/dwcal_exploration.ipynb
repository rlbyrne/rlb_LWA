{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c948c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import pyuvdata\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165bd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(use_autos=True):\n",
    "\n",
    "    model_path = '/Users/ruby/Astro/FHD_outputs/fhd_rlb_model_GLEAM_Aug2021'\n",
    "    model_use_model = True\n",
    "    data_path = '/Users/ruby/Astro/FHD_outputs/fhd_rlb_model_GLEAM_Aug2021'\n",
    "    data_use_model = True\n",
    "    obsid = '1061316296'\n",
    "    pol = 'XX'\n",
    "\n",
    "    model_filelist = ['{}/{}'.format(model_path, file) for file in [\n",
    "        'vis_data/{}_vis_{}.sav'.format(obsid, pol),\n",
    "        'vis_data/{}_vis_model_{}.sav'.format(obsid, pol),\n",
    "        'vis_data/{}_flags.sav'.format(obsid),\n",
    "        'metadata/{}_params.sav'.format(obsid),\n",
    "        'metadata/{}_settings.txt'.format(obsid),\n",
    "        'metadata/{}_layout.sav'.format(obsid)\n",
    "    ]]\n",
    "    data_filelist = ['{}/{}'.format(data_path, file) for file in [\n",
    "        'vis_data/{}_vis_{}.sav'.format(obsid, pol),\n",
    "        'vis_data/{}_vis_model_{}.sav'.format(obsid, pol),\n",
    "        'vis_data/{}_flags.sav'.format(obsid),\n",
    "        'metadata/{}_params.sav'.format(obsid),\n",
    "        'metadata/{}_settings.txt'.format(obsid),\n",
    "        'metadata/{}_layout.sav'.format(obsid)\n",
    "    ]]\n",
    "\n",
    "    model = pyuvdata.UVData()\n",
    "    print('Reading model...')\n",
    "    model.read_fhd(model_filelist, use_model=model_use_model)\n",
    "    \n",
    "    # For testing, use one time and a few frequencies only\n",
    "    use_time = model.time_array[200000]\n",
    "    use_frequencies = model.freq_array[0, 100:200]\n",
    "    #use_frequencies = data.freq_array[0, :]\n",
    "    model.select(times=use_time, frequencies=use_frequencies)\n",
    "\n",
    "    if not use_autos:  # Remove autocorrelations\n",
    "        bl_lengths = np.sqrt(np.sum(model.uvw_array**2., axis=1))\n",
    "        non_autos = np.where(bl_lengths > 0.01)[0]\n",
    "        model.select(blt_inds=non_autos)\n",
    "\n",
    "    if data_path != model_path or model_use_model != data_use_model:\n",
    "        data = pyuvdata.UVData()\n",
    "        print('Reading data...')\n",
    "        data.read_fhd(data_filelist, use_model=data_use_model)\n",
    "        print('Done.')\n",
    "        data.select(times=use_time, frequencies=use_frequencies)\n",
    "        if not use_autos:  # Remove autocorrelations\n",
    "            bl_lengths = np.sqrt(np.sum(data.uvw_array**2., axis=1))\n",
    "            non_autos = np.where(bl_lengths > 0.01)[0]\n",
    "            data.select(blt_inds=non_autos)\n",
    "    else:\n",
    "        print('Using model for data')\n",
    "        data = model.copy()\n",
    "        \n",
    "    # Need to check that the baseline ordering agrees between model and data\n",
    "\n",
    "    return data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a18e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cal(data):\n",
    "\n",
    "    cal = pyuvdata.UVCal()\n",
    "    cal.Nants_data = data.Nants_data\n",
    "    cal.Nants_telescope = data.Nants_telescope\n",
    "    cal.Nfreqs = data.Nfreqs\n",
    "    cal.Njones = 1\n",
    "    cal.Nspws = 1\n",
    "    cal.Ntimes = 1\n",
    "    cal.ant_array = np.arange(data.Nants_data)\n",
    "    cal.antenna_names = data.antenna_names\n",
    "    cal.antenna_numbers = data.antenna_numbers\n",
    "    cal.cal_style = 'sky'\n",
    "    cal.cal_type = 'gain'\n",
    "    cal.channel_width = data.channel_width\n",
    "    cal.freq_array = data.freq_array\n",
    "    cal.gain_convention = 'divide'\n",
    "    cal.history = ''\n",
    "    cal.integration_time = np.mean(data.integration_time)\n",
    "    cal.jones_array = np.array([-5])\n",
    "    cal.spw_array = data.spw_array\n",
    "    cal.telescope_name = data.telescope_name\n",
    "    cal.time_array = np.array([np.mean(data.time_array)])\n",
    "    cal.x_orientation = 'east'\n",
    "    cal.gain_array = np.full((\n",
    "        cal.Nants_data, cal.Nspws, cal.Nfreqs, cal.Ntimes, cal.Njones\n",
    "    ), 1, dtype=complex)\n",
    "    cal.flag_array = np.full((\n",
    "        cal.Nants_data, cal.Nspws, cal.Nfreqs, cal.Ntimes, cal.Njones\n",
    "    ), False, dtype=bool)\n",
    "    cal.quality_array = np.full((\n",
    "        cal.Nants_data, cal.Nspws, cal.Nfreqs, cal.Ntimes, cal.Njones\n",
    "    ), 1., dtype=float)\n",
    "    cal.ref_antenna_name = ''\n",
    "    cal.sky_catalog = 'GLEAM_bright_sources'\n",
    "    cal.sky_field = 'phase center (RA, Dec): ({}, {})'.format(\n",
    "        np.degrees(np.mean(data.phase_center_app_ra)),\n",
    "        np.degrees(np.mean(data.phase_center_app_dec))\n",
    "    )\n",
    "\n",
    "    if not cal.check():\n",
    "        print('ERROR: UVCal check failed.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    return cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d1cf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Telescope location derived from obs lat/lon/alt values does not match the location in the layout file. Using the value from known_telescopes.\n",
      "tile_names from obs structure does not match antenna_names from layout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model for data\n"
     ]
    }
   ],
   "source": [
    "data, model = get_test_data(use_autos=False)\n",
    "\n",
    "cal = initialize_cal(data)\n",
    "\n",
    "# Create gains expand matrices\n",
    "gains_exp_mat_1 = np.zeros((data.Nblts, cal.Nants_data), dtype=int)\n",
    "gains_exp_mat_2 = np.zeros((data.Nblts, cal.Nants_data), dtype=int)\n",
    "antenna_list = np.unique([data.ant_1_array, data.ant_2_array])\n",
    "for baseline in range(data.Nblts):\n",
    "    gains_exp_mat_1[\n",
    "        baseline, np.where(antenna_list == data.ant_1_array[baseline])\n",
    "    ] = 1\n",
    "    gains_exp_mat_2[\n",
    "        baseline, np.where(antenna_list == data.ant_2_array[baseline])\n",
    "    ] = 1\n",
    "    \n",
    "# Test gains expand matrices\n",
    "gains_exp_mat_1_test = np.sum(gains_exp_mat_1, axis=1)\n",
    "gains_exp_mat_2_test = np.sum(gains_exp_mat_2, axis=1)\n",
    "if np.max(gains_exp_mat_1_test) > 1 or np.max(gains_exp_mat_2_test) > 1:\n",
    "    print('ERROR: Poorly defined gains expand matrices')\n",
    "    sys.exit()\n",
    "\n",
    "# Initialize gains\n",
    "gain_init_noise = .1\n",
    "#gain_init_noise = 0.\n",
    "gains_init = (np.random.normal(\n",
    "    1., gain_init_noise, size=(cal.Nants_data, cal.Nfreqs)\n",
    ") + 1.j*np.random.normal(\n",
    "    0., gain_init_noise, size=(cal.Nants_data, cal.Nfreqs)\n",
    "))\n",
    "\n",
    "# Define covariance matrix\n",
    "cov_mat = np.identity(cal.Nfreqs)\n",
    "cov_mat = np.repeat(cov_mat[np.newaxis, :, :], data.Nblts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34cf0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = gains_init\n",
    "model_vis = np.squeeze(model.data_array, axis=(1,3)) # Remove spw and pol axes\n",
    "data_vis = np.squeeze(data.data_array, axis=(1,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbf8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grad_real(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat):\n",
    "    gains1_expanded = np.matmul(gains_exp_mat_1, gains)\n",
    "    gains2_expanded = np.matmul(gains_exp_mat_2, gains)\n",
    "    term1_part1 = -np.conj(gains1_expanded*model_vis)\n",
    "    term2_part1 = -gains2_expanded*np.conj(model_vis)\n",
    "    cost_term = data_vis - gains1_expanded*np.conj(gains2_expanded)*model_vis\n",
    "    weighted_part2 = np.squeeze(np.matmul(cost_term[:, np.newaxis, :], cov_mat))\n",
    "    term1 = np.matmul(gains_exp_mat_2.T, term1_part1*weighted_part2)\n",
    "    term2 = np.matmul(gains_exp_mat_1.T, term2_part1*weighted_part2)\n",
    "    grad = 2*np.real(term1 + term2)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7849aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_grad_imag(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat):\n",
    "    gains1_expanded = np.matmul(gains_exp_mat_1, gains)\n",
    "    gains2_expanded = np.matmul(gains_exp_mat_2, gains)\n",
    "    term1_part1 = -1.j*np.conj(gains1_expanded*model_vis)\n",
    "    term2_part1 = 1.j*gains2_expanded*np.conj(model_vis)\n",
    "    cost_term = data_vis - gains1_expanded*np.conj(gains2_expanded)*model_vis\n",
    "    weighted_part2 = np.squeeze(np.matmul(cost_term[:, np.newaxis, :], cov_mat))\n",
    "    term1 = np.matmul(gains_exp_mat_2.T, term1_part1*weighted_part2)\n",
    "    term2 = np.matmul(gains_exp_mat_1.T, term2_part1*weighted_part2)\n",
    "    grad = 2*np.real(term1 + term2)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db93a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_negloglikelihood(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat):\n",
    "    gains1_expanded = np.matmul(gains_exp_mat_1, gains)\n",
    "    gains2_expanded = np.matmul(gains_exp_mat_2, gains)\n",
    "    cost_term = data_vis - gains1_expanded*np.conj(gains2_expanded)*model_vis\n",
    "    weighted_part2 = np.squeeze(np.matmul(cost_term[:, np.newaxis, :], cov_mat))\n",
    "    negloglikelihood = np.real(np.sum(np.conj(cost_term)*weighted_part2))\n",
    "    return negloglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ccb4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13999.901879578829\n",
      "13999.901875868476\n"
     ]
    }
   ],
   "source": [
    "# Test real gradient calculation\n",
    "test_ant = 100\n",
    "test_freq = 1\n",
    "delta_gains = 0.0001\n",
    "gains0 = np.copy(gains)\n",
    "gains0[test_ant, test_freq] -= delta_gains/2.\n",
    "gains1 = np.copy(gains)\n",
    "gains1[test_ant, test_freq] += delta_gains/2.\n",
    "negloglikelihood0 = calculate_negloglikelihood(gains_exp_mat_1, gains_exp_mat_2, gains0, data_vis, model_vis, cov_mat)\n",
    "negloglikelihood1 = calculate_negloglikelihood(gains_exp_mat_1, gains_exp_mat_2, gains1, data_vis, model_vis, cov_mat)\n",
    "grad_real = calculate_grad_real(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat)\n",
    "print((negloglikelihood1-negloglikelihood0)/delta_gains)\n",
    "print(grad_real[test_ant, test_freq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87bc081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3450.250495225191\n",
      "-3450.250514227262\n"
     ]
    }
   ],
   "source": [
    "# Test imaginary gradient calculation\n",
    "test_ant = 100\n",
    "test_freq = 1\n",
    "delta_gains = 0.0001\n",
    "gains0 = np.copy(gains)\n",
    "gains0[test_ant, test_freq] -= 1j*delta_gains/2.\n",
    "gains1 = np.copy(gains)\n",
    "gains1[test_ant, test_freq] += 1j*delta_gains/2.\n",
    "negloglikelihood0 = calculate_negloglikelihood(gains_exp_mat_1, gains_exp_mat_2, gains0, data_vis, model_vis, cov_mat)\n",
    "negloglikelihood1 = calculate_negloglikelihood(gains_exp_mat_1, gains_exp_mat_2, gains1, data_vis, model_vis, cov_mat)\n",
    "grad_imag = calculate_grad_imag(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat)\n",
    "print((negloglikelihood1-negloglikelihood0)/delta_gains)\n",
    "print(grad_imag[test_ant, test_freq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "090bdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_baselines_to_antenna_matrix(bl_array, gains_exp_mat_1, gains_exp_mat_2):\n",
    "    (Nbls, Nants) = np.shape(gains_exp_mat_1)\n",
    "    antenna_matrix = np.zeros_like(bl_array[0,], dtype=bl_array.dtype)\n",
    "    antenna_matrix = np.repeat(np.repeat(antenna_matrix[np.newaxis,], Nants, axis=0)[np.newaxis,], Nants, axis=0)\n",
    "    antenna_numbers = np.arange(Nants)\n",
    "    antenna1_num = np.matmul(gains_exp_mat_1, antenna_numbers)\n",
    "    antenna2_num = np.matmul(gains_exp_mat_2, antenna_numbers)\n",
    "    for bl_ind in range(Nbls):\n",
    "        antenna_matrix[antenna1_num[bl_ind], antenna2_num[bl_ind], ] = bl_array[bl_ind, ]\n",
    "    return(antenna_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a48326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hess(\n",
    "    gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat,\n",
    "    Nants,\n",
    "    Nfreqs,\n",
    "    Nblts\n",
    "):\n",
    "    gains1_expanded = np.matmul(gains_exp_mat_1, gains)\n",
    "    gains2_expanded = np.matmul(gains_exp_mat_2, gains)\n",
    "    \n",
    "    gains1_times_model = gains1_expanded*model_vis\n",
    "    gains2_times_conj_model = gains2_expanded*np.conj(model_vis)\n",
    "    \n",
    "    term1 = (\n",
    "        gains1_times_model[:, np.newaxis, :]\n",
    "        *gains2_times_conj_model[:, :, np.newaxis]\n",
    "        *np.conj(cov_mat)\n",
    "    )\n",
    "    term1 = reformat_baselines_to_antenna_matrix(term1, gains_exp_mat_1, gains_exp_mat_2)\n",
    "    term1 = np.transpose(term1, (1, 0, 2, 3))\n",
    "    term2 = (\n",
    "        gains2_times_conj_model[:, np.newaxis, :]\n",
    "        *gains1_times_model[:, :, np.newaxis]\n",
    "        *cov_mat\n",
    "    )\n",
    "    term2 = reformat_baselines_to_antenna_matrix(term2, gains_exp_mat_1, gains_exp_mat_2)\n",
    "    combined_terms = 2*(term1 + term2)\n",
    "    \n",
    "    # hess elements are antenna_c, antenna_d, freq_f0, freq_f1, and real/imag pair\n",
    "    # The real/imag pairs are in order real-real, real-imag, and imag-imag\n",
    "    hess = np.zeros((Nants, Nants, Nfreqs, Nfreqs, 3), dtype=float)\n",
    "    hess[:, :, :, :, 0] = np.real(combined_terms)\n",
    "    hess[:, :, :, :, 1] = np.imag(combined_terms)\n",
    "    hess[:, :, :, :, 2] = -np.real(combined_terms)\n",
    "\n",
    "    cost_func = np.conj(model_vis)*np.sum(\n",
    "        cov_mat*(data_vis - gains1_expanded*np.conj(gains2_expanded)*model_vis)[:, :, np.newaxis],\n",
    "        axis=2\n",
    "    )\n",
    "    cost_func = reformat_baselines_to_antenna_matrix(cost_func, gains_exp_mat_1, gains_exp_mat_2)\n",
    "    cost_func_transpose = np.transpose(np.conj(cost_func), (1, 0, 2))\n",
    "    freq_diagonals = -2*(cost_func + cost_func_transpose)\n",
    "    for freq in range(Nfreqs):\n",
    "        hess[:, :, freq, freq, 0] += np.real(freq_diagonals[:, :, freq])\n",
    "        hess[:, :, freq, freq, 1] += np.imag(freq_diagonals[:, :, freq])\n",
    "        hess[:, :, freq, freq, 2] += np.real(freq_diagonals[:, :, freq])\n",
    "        \n",
    "    if False: # Test reformatting\n",
    "        hess_reformatted = np.zeros(\n",
    "            (2, 2, Nants*Nfreqs, Nants*Nfreqs), dtype=float\n",
    "        )\n",
    "        hess_reformatted[0, 0, :, :] = hess[:, :, :, :, 0].reshape(\n",
    "            Nants*Nfreqs, Nants*Nfreqs\n",
    "        )\n",
    "        hess_reformatted[0, 1, :, :] = hess[:, :, :, :, 1].reshape(\n",
    "            Nants*Nfreqs, Nants*Nfreqs\n",
    "        )\n",
    "        hess_reformatted[1, 0, :, :] = (hess[:, :, :, :, 1].reshape(\n",
    "            Nants*Nfreqs, Nants*Nfreqs)\n",
    "        ).T\n",
    "        hess_reformatted[1, 1, :, :] = hess[:, :, :, :, 2].reshape(\n",
    "            Nants*Nfreqs, Nants*Nfreqs\n",
    "        )\n",
    "        del hess\n",
    "        hess_reformatted = hess_reformatted.reshape(2*Nants*Nfreqs, 2*Nants*Nfreqs)\n",
    "\n",
    "        hess_reformatted = hess_reformatted.reshape(2, 2, Nants, Nants, Nfreqs, Nfreqs)\n",
    "        hess = np.zeros((Nants, Nants, Nfreqs, Nfreqs, 3), dtype=float)\n",
    "        hess[:, :, :, :, 0] = hess_reformatted[0, 0, :, :, :, :]\n",
    "        hess[:, :, :, :, 1] = hess_reformatted[0, 1, :, :, :, :]\n",
    "        hess[:, :, :, :, 2] = hess_reformatted[1, 1, :, :, :, :]\n",
    "\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e796ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc612d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786.2404964544112\n",
      "786.2404964529857\n"
     ]
    }
   ],
   "source": [
    "# Test real-real Hessian calculation\n",
    "test_ant = 4\n",
    "test_freq = 2\n",
    "readout_ant = 5\n",
    "readout_freq = 2\n",
    "delta_gains = 0.0001\n",
    "gains0 = np.copy(gains)\n",
    "gains0[test_ant, test_freq] -= delta_gains/2.\n",
    "gains1 = np.copy(gains)\n",
    "gains1[test_ant, test_freq] += delta_gains/2.\n",
    "grad0 = calculate_grad_real(gains_exp_mat_1, gains_exp_mat_2, gains0, data_vis, model_vis, cov_mat)\n",
    "grad1 = calculate_grad_real(gains_exp_mat_1, gains_exp_mat_2, gains1, data_vis, model_vis, cov_mat)\n",
    "hess = calculate_hess(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat, cal.Nants_data, cal.Nfreqs, data.Nblts)\n",
    "print((grad1[readout_ant, readout_freq]-grad0[readout_ant, readout_freq])/delta_gains)\n",
    "print(hess[test_ant, readout_ant, test_freq, readout_freq, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac0ab78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.42852439553826\n",
      "70.42852439752825\n"
     ]
    }
   ],
   "source": [
    "# Test real-imag Hessian calculation\n",
    "test_ant = 4\n",
    "test_freq = 2\n",
    "readout_ant = 5\n",
    "readout_freq = 2\n",
    "delta_gains = 0.0001\n",
    "gains0 = np.copy(gains)\n",
    "gains0[test_ant, test_freq] -= 1j*delta_gains/2.\n",
    "gains1 = np.copy(gains)\n",
    "gains1[test_ant, test_freq] += 1j*delta_gains/2.\n",
    "grad0 = calculate_grad_real(gains_exp_mat_1, gains_exp_mat_2, gains0, data_vis, model_vis, cov_mat)\n",
    "grad1 = calculate_grad_real(gains_exp_mat_1, gains_exp_mat_2, gains1, data_vis, model_vis, cov_mat)\n",
    "hess = calculate_hess(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat, cal.Nants_data, cal.Nfreqs, data.Nblts)\n",
    "print((grad1[readout_ant, readout_freq]-grad0[readout_ant, readout_freq])/delta_gains)\n",
    "print(hess[test_ant, readout_ant, test_freq, readout_freq, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0d01fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-612.2603700168838\n",
      "-612.2603700065032\n"
     ]
    }
   ],
   "source": [
    "# Test imag-imag Hessian calculation\n",
    "test_ant = 4\n",
    "test_freq = 2\n",
    "readout_ant = 5\n",
    "readout_freq = 2\n",
    "delta_gains = 0.0001\n",
    "gains0 = np.copy(gains)\n",
    "gains0[test_ant, test_freq] -= 1j*delta_gains/2.\n",
    "gains1 = np.copy(gains)\n",
    "gains1[test_ant, test_freq] += 1j*delta_gains/2.\n",
    "grad0 = calculate_grad_imag(gains_exp_mat_1, gains_exp_mat_2, gains0, data_vis, model_vis, cov_mat)\n",
    "grad1 = calculate_grad_imag(gains_exp_mat_1, gains_exp_mat_2, gains1, data_vis, model_vis, cov_mat)\n",
    "hess = calculate_hess(gains_exp_mat_1, gains_exp_mat_2, gains, data_vis, model_vis, cov_mat, cal.Nants_data, cal.Nfreqs, data.Nblts)\n",
    "print((grad1[readout_ant, readout_freq]-grad0[readout_ant, readout_freq])/delta_gains)\n",
    "print(hess[test_ant, readout_ant, test_freq, readout_freq, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4945d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
